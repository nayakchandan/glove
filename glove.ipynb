{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT STATEMENTS\n",
    "import numpy as np\n",
    "import sys\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Glo**bal **Ve**ctors or Glove for short is an unsupervised ML algorithm used for converting words into vectors which encode semantic relationships. [Here](https://nlp.stanford.edu/pubs/glove.pdf) is the paper from the Stanford NLP team that introduced Glove to the NLP world. The nice folks at Stanford NLP team have pre-trained the Glove model on large text corpora and have [shared them](https://nlp.stanford.edu/projects/glove/) for public use. We can use a pre-trained glove model for our NLP tasks - like article recommendation or just play around with it! This notebook should help you get familiar with the glove file and how to load it in Python for further use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The glove file is just a simple text file with each row containing an English word and then a set of numbers that determine the orientation of that word's vector representation in a high dimensional space. As each word is represented by vectors, we can perform vector operations like computing the Euclidian distance. Infact, this will be our approach for finding words that are closest to a word. Now these closest words need not be synonymns as we shall see. Infact, glove model embeds some interesting relationships that is surprisngly powerful.\n",
    "\n",
    "We load the glove file into a dictionary with the word as a key and its vector dimensions as a numpy array assigned to it. We do remove stop words as well and we load the words line-by-line to make sure this operations works on even machines with low resources. The entire operation of loading the 'glove.6B.300d.txt' glove file took about 22s on my Macbook Pro 16 inch and I suppose more able machines can load this faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = list(stopwords.words('english'))\n",
    "punctuation = list(string.punctuation)\n",
    "stop_words.extend(punctuation)\n",
    "glove = {}\n",
    "with open('glove.6B.300d.txt',encoding='utf-8',mode='r') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.split()\n",
    "        if line[0] not in stop_words:\n",
    "            glove[line[0]] = np.array(line[1:],dtype=np.float32)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a function that takes in a word and a glove file to return the n words present in the glove dictionary that are closest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(v1,v2):\n",
    "    ''' \n",
    "    Takes in two vectors and returns the euclidian distance between them\n",
    "    '''\n",
    "    return np.linalg.norm(v1-v2)\n",
    "\n",
    "\n",
    "def top_n_closest_words(word,glove,n):\n",
    "    ''' \n",
    "    Given a word and a glove dictionary object, returns the n closest words\n",
    "    '''\n",
    "\n",
    "    # We will append (word1, distance from word) where word1 is present as keys in glove dictionary\n",
    "    result = []\n",
    "\n",
    "    for key in glove.keys():\n",
    "        dist = distance(glove[key],glove[word])\n",
    "        result.append((key,dist))\n",
    "\n",
    "    #sort based on keys:\n",
    "    result = sorted(result,key=lambda x: x[1])\n",
    "\n",
    "    # The first closest word is the word itself, so we start our index from 1\n",
    "    return result[1:n+1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the power of glove vectors, lets look at the 10 closest words to 'ally'. Do you notice the second entry 'staunch'? This is because both of them appear a lot (like '...is a staunch ally...') together and therefore are close to each other. We see synonyms as well as antonymns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('allies', 4.8981414),\n",
       " ('staunch', 5.6140485),\n",
       " ('stalwart', 5.660538),\n",
       " ('supporter', 5.893143),\n",
       " ('backer', 5.9614644),\n",
       " ('longtime', 6.0186133),\n",
       " ('adversary', 6.028124),\n",
       " ('adversaries', 6.061235),\n",
       " ('foe', 6.071723),\n",
       " ('considers', 6.216141)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_closest_words('ally',glove,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even use glove to infer relationships using simple arithmetic like, 'uncle'-'man'+'woman' = 'aunt'!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove['test_string'] = glove['uncle'] - glove['man'] + glove['woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'test_string'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aunt', 4.668237),\n",
       " ('niece', 4.720575),\n",
       " ('uncle', 4.7539396),\n",
       " ('grandmother', 4.8348556),\n",
       " ('mother', 5.1565957)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_closest_words(test,glove,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51257e3d6adcf4f249880334112f68e609bc91a365f964b61c4cee61bd4b0e6f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
